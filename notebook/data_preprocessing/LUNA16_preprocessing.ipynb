{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os.path import join as jp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "\n",
    "from dpipe.io import load_json, save_json\n",
    "from dpipe.medim.box import limit_box, add_margin, mask2bounding_box\n",
    "from iw.cv import fill3d\n",
    "from iw.xml_parsing import id2root, root2expert_roots, expert_root2nodules, nodules2centers, get_nodules\n",
    "from iw.io import load_itkimage_ct, load_itkimage_lungmask, itkimage2image, load_nii, save_nii, get_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Unpacking the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from iw.path_local import luna_raw_path\n",
    "from iw.path import luna_raw_path\n",
    "raw_dp = luna_raw_path\n",
    "\n",
    "xml_dp = jp(raw_dp, 'tcia-lidc-xml/')\n",
    "lung_mask_dp = jp(raw_dp, 'seg-lungs-LUNA16/')\n",
    "nodules_dp = jp(raw_dp, 'annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodules_df = pd.read_csv(nodules_dp, index_col='seriesuid')\n",
    "nodules_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subsets = 10\n",
    "n_train, n_val, n_holdout = 6, 2, 2\n",
    "\n",
    "subset_ids = np.arange(n_subsets)\n",
    "\n",
    "ids = dict()\n",
    "ids['train'], ids['val'], ids['holdout'] = map(lambda x: get_ids(raw_dp, x), (subset_ids[:n_train], \n",
    "                                                                              subset_ids[n_train:-n_holdout], \n",
    "                                                                              subset_ids[-n_holdout:]))\n",
    "with open('reverse_ids.json', 'r') as f:\n",
    "    reverse_ids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_centers(_id: str, nodules_df: pd.DataFrame) -> (list, bool):\n",
    "    \"\"\"Gets absolute coordinates of nodule centers by id.\"\"\"\n",
    "\n",
    "    abs_coords = []\n",
    "    no_nodules = True\n",
    "\n",
    "    if _id in nodules_df.index:\n",
    "        abs_coords = nodules_df[['coordX', 'coordY', 'coordZ']].loc[_id].values\n",
    "        no_nodules = False\n",
    "\n",
    "        if len(np.shape(abs_coords)) == 1:\n",
    "            abs_coords = np.array([abs_coords])\n",
    "\n",
    "    return abs_coords, no_nodules\n",
    "\n",
    "\n",
    "def absolute2relative(abs_coords: np.ndarray, origin: np.ndarray, spacing: np.ndarray) -> list:\n",
    "    \"\"\"Shifts absolute coordinates into the relative.\"\"\"\n",
    "\n",
    "    rel_coords = []\n",
    "\n",
    "    for abs_c in abs_coords:\n",
    "        rel_c = np.int64(np.round((abs_c - origin) / spacing))\n",
    "        assert np.all(rel_c > 0)\n",
    "        rel_coords.append(rel_c)\n",
    "\n",
    "    return rel_coords\n",
    "\n",
    "\n",
    "def center2hit(center: list, rel_centers: list, r: int) -> bool:\n",
    "    is_hit = False\n",
    "    for rel_center in rel_centers:\n",
    "        if np.linalg.norm(np.array(center) - np.array(rel_center)) <= r:\n",
    "            is_hit = True\n",
    "\n",
    "    return is_hit\n",
    "\n",
    "\n",
    "def nodules2target(target: np.ndarray, expert_nodules: list, rel_centers: list,\n",
    "                   origin: np.ndarray, spacing: np.ndarray, r=10) -> np.ndarray:\n",
    "    \"\"\"Builds segmentation mask from the given expert delineation.\"\"\"\n",
    "\n",
    "    for nodules in expert_nodules:\n",
    "        centers = nodules2centers(nodules, origin[-1], spacing[-1])\n",
    "\n",
    "        for center, nodule in zip(centers, nodules):\n",
    "            if center2hit(center, rel_centers, r=r):\n",
    "                target += fill3d(np.zeros_like(target), nodule, origin[-1], spacing[-1])\n",
    "                \n",
    "    n_experts = 4\n",
    "\n",
    "    return np.float32(target / n_experts >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(_id: str, raw_dp: str, xml_dp: str, lung_mask_dp: str):\n",
    "    \n",
    "    # CT\n",
    "    itkimage_ct = load_itkimage_ct(_id, raw_dp)\n",
    "    ct = itkimage2image(itkimage_ct)\n",
    "    \n",
    "    \n",
    "    # lung_mask\n",
    "    itkimage_lung_mask = load_itkimage_lungmask(_id, lung_mask_dp)\n",
    "    lung_mask = itkimage2image(itkimage_lung_mask)\n",
    "    \n",
    "    \n",
    "    # origin, spacing\n",
    "    origin, spacing = map(np.array, (itkimage_ct.GetOrigin(), itkimage_ct.GetSpacing()))\n",
    "\n",
    "    \n",
    "    # \"tumor_data\": nodules' centers, diameters\n",
    "    abs_centers, no_tumor = get_absolute_centers(_id, nodules_df)\n",
    "    if _id in reverse_ids:\n",
    "        abs_centers[:, :2] = 2 * origin[:2] - abs_centers[:, :2]\n",
    "        \n",
    "    rel_centers = absolute2relative(abs_centers, origin, spacing)\n",
    "    \n",
    "    if not no_tumor:\n",
    "        try:\n",
    "            diameters = list(nodules_df.loc[_id]['diameter_mm'])\n",
    "        except TypeError:\n",
    "            diameters = list([nodules_df.loc[_id]['diameter_mm']])\n",
    "    else:\n",
    "        diameters = []\n",
    "        \n",
    "    tumor_data = [{'center': abs_c, 'diameter': d} for abs_c, d in zip(abs_centers, diameters)]\n",
    "    \n",
    "    \n",
    "    # target    \n",
    "    target = np.zeros_like(ct, dtype='float32')\n",
    "    if not no_tumor:\n",
    "        expert_nodules = get_nodules(_id, xml_dp)\n",
    "        target = nodules2target(target, expert_nodules, rel_centers, origin, spacing)\n",
    "    \n",
    "    \n",
    "    return ct, target, lung_mask, origin, spacing, tumor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_trachea(lung_mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Excludes trachea's class from the lungs\\' mask.\"\"\"\n",
    "\n",
    "    labels, volumes = np.unique(lung_mask, return_counts=True)\n",
    "    trachea_label = labels[np.argmin(volumes)]\n",
    "    lung_mask[lung_mask == trachea_label] = 0\n",
    "\n",
    "    return lung_mask\n",
    "\n",
    "\n",
    "def mask2bbox(mask: np.ndarray, margin=0) -> np.ndarray:\n",
    "    \"\"\"Creates valid bounding box with a specified margin.\"\"\"\n",
    "\n",
    "    box = limit_box(add_margin(mask2bounding_box(mask), margin), mask.shape)\n",
    "    return box\n",
    "\n",
    "\n",
    "def crop2box(image: np.ndarray, box: np.ndarray) -> np.ndarray:\n",
    "    return image[box[0, 0]:box[1, 0],\n",
    "                 box[0, 1]:box[1, 1],\n",
    "                 box[0, 2]:box[1, 2]]\n",
    "\n",
    "\n",
    "def mask2closed_mask(mask: np.ndarray, margin=1) -> np.ndarray:\n",
    "    \"\"\"Creates closed mask around the given mask with specified margin.\"\"\"\n",
    "\n",
    "    if margin > 0:\n",
    "        for _ in range(margin):\n",
    "            mask = binary_dilation(mask)\n",
    "\n",
    "        for _ in range(margin):\n",
    "            mask = binary_erosion(mask)\n",
    "\n",
    "    return mask.astype('int64')\n",
    "\n",
    "\n",
    "def mask2dilated_mask(mask: np.ndarray, margin=1) -> np.ndarray:\n",
    "    \"\"\"Creates closed mask around the given mask with specified margin.\"\"\"\n",
    "\n",
    "    if margin > 0:\n",
    "        for _ in range(margin):\n",
    "            mask = binary_dilation(mask)\n",
    "\n",
    "    return mask.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_set(_id, ct, target, lung_mask, origin, spacing, tumor_data):    \n",
    "    lung_mask = mask2dilated_mask(mask2closed_mask(drop_trachea(lung_mask), margin=10), margin=3)\n",
    "    \n",
    "    \n",
    "    box = mask2bbox(lung_mask, margin=5)\n",
    "    cropped_ct, cropped_target, cropped_lung_mask = [crop2box(scan, box) for scan in [ct, target, lung_mask]]\n",
    "    \n",
    "    \n",
    "    shifted_tumor_data = []\n",
    "    if np.any(tumor_data):\n",
    "        for tumor in tumor_data:\n",
    "            abs_c, d = tumor['center'], tumor['diameter'] \n",
    "            shifted_tumor_data.append({'center': list(abs_c - box[0] * spacing + origin), \n",
    "                                       'diameter': d,\n",
    "                                       'abs_shift_mm': box[0] * spacing - origin})\n",
    "            \n",
    "    return cropped_ct, cropped_target, cropped_lung_mask, origin, spacing, shifted_tumor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dump the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(split: str, save_dp: str, _id: str, \n",
    "                  ct: np.ndarray, target: np.ndarray, lung_mask: np.ndarray, \n",
    "                  origin: np.ndarray, spacing: np.ndarray, tumor_data: list) -> dict:\n",
    "    os.makedirs(jp(save_dp, split, _id), exist_ok=True)\n",
    "\n",
    "    record = {\n",
    "        'id': _id,\n",
    "        'CT': jp(_id, 'CT.nii.gz'),\n",
    "        'target': jp(_id, 'target.nii.gz'),\n",
    "        'lung_mask': jp(_id, 'lung_mask.nii.gz'),\n",
    "        'origin': jp(_id, 'origin.json'),\n",
    "        'spacing': jp(_id, 'spacing.json'),\n",
    "        'n_tumors': len(tumor_data) if np.any(tumor_data) else 0,\n",
    "        'tumor_data': jp(_id, 'tumors.json'),\n",
    "        'split': split\n",
    "    }\n",
    "\n",
    "    save_nii(jp(save_dp, split, record['CT']), np.array(ct, dtype='float32'))\n",
    "    save_nii(jp(save_dp, split, record['target']), np.array(target, dtype='float32'))\n",
    "    save_nii(jp(save_dp, split, record['lung_mask']), np.array(lung_mask, dtype='float32'))\n",
    "\n",
    "    save_json(origin, jp(save_dp, split, record['origin']))\n",
    "    save_json(spacing, jp(save_dp, split, record['spacing']))\n",
    "    save_json(tumor_data, jp(save_dp, split, record['tumor_data']))\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def dump(split: str, save_dp: str, ids=ids, raw_dp=raw_dp, xml_dp=xml_dp, lung_mask_dp=lung_mask_dp,  \n",
    "         preprocessing=True) -> None:\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    with open('outlier_ids.json', 'r') as f:\n",
    "        outlier_ids = json.load(f)\n",
    "    \n",
    "    for _id in tqdm.notebook.tqdm(ids[split]):\n",
    "        if _id not in outlier_ids:\n",
    "            _set = get_set(_id, raw_dp, xml_dp, lung_mask_dp)\n",
    "            if preprocessing:\n",
    "                _set = preprocess_set(_id, *_set)\n",
    "\n",
    "            record = create_record(split, save_dp, _id, *_set)\n",
    "            records.append(record)\n",
    "\n",
    "    metadata = pd.DataFrame.from_records(records, index='id')\n",
    "    metadata.to_csv(path_or_buf=jp(save_dp, split, 'metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from iw.path_local import luna_data_path\n",
    "from iw.path import luna_data_path\n",
    "save_dp = luna_data_path\n",
    "\n",
    "dump('train', save_dp, preprocessing=True)\n",
    "dump('val', save_dp, preprocessing=True)\n",
    "dump('holdout', save_dp, preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Merge metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(jp(save_dp, 'train/metadata.csv'), index_col='id')\n",
    "df_v = pd.read_csv(jp(save_dp, 'val/metadata.csv'), index_col='id')\n",
    "df_h = pd.read_csv(jp(save_dp, 'holdout/metadata.csv'), index_col='id')\n",
    "df = pd.concat((df_t, df_v, df_h))\n",
    "\n",
    "for _id in df.index:\n",
    "    row = df.loc[_id]\n",
    "    for c in df.columns:\n",
    "        if c != 'n_tumors' and c != 'split':\n",
    "            df[c].loc[_id] = row['split'] + '/' + row[c]\n",
    "            \n",
    "df.to_csv(jp(save_dp, 'metadata.csv'), index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
