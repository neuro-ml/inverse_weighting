from functools import partial

import torch

import dpipe.commands as commands
from dpipe.config import if_missing, lock_dir
from dpipe.io import ConsoleArguments, load_json
from dpipe.medim.utils import identity
from dpipe.experiment import flat
from dpipe.train import train, CheckpointManager, Policy
from dpipe.train.logging import TBLogger
from dpipe.train.policy import Schedule
from dpipe.train.validator import compute_metrics
from dpipe.torch.functional import weighted_cross_entropy_with_logits
from dpipe.torch import save_model_state, load_model_state
from iw.torch import train_step_with_cc
from iw.metric import evaluate_individual_metrics_with_prc
from iw.utils import fix_seed


console = ConsoleArguments()

# ### 1. PATHS and IDS ###

config_path = console(config_path=__file__)
experiment_path = console.experiment_path

log_path = 'train_logs'
saved_model_path = 'model.pth'
test_predictions_path = 'test_predictions'
logit_predictions_path = 'logit_predictions'
checkpoints_path = 'checkpoints'

train_ids = load_json('train_ids.json')
val_ids = load_json('val_ids.json')
test_ids = load_json('test_ids.json')

# ### 2. BUILD EXPERIMENT ###

n_chans_in = dataset.n_chans_image
n_chans_out = 1

load_x = dataset.load_image
load_y = dataset.load_segm

build_experiment = flat(
    config_path=config_path,
    experiment_path=experiment_path,
    split=split
)

# ### 3. TRAIN MODEL ###

# 3.1. hyper parameters, lr policy, optimizer
n_epochs = 100
batches_per_epoch = 100

lr_init = 1e-2
epoch2lr_dec_mul = {80: 0.1, }
lr_policy = Schedule(initial=lr_init, epoch2value_multiplier=epoch2lr_dec_mul)
policies = {}

device = 'cuda'

optimizer = torch.optim.SGD(
    architecture.parameters(),
    lr=lr_init,
    momentum=0.9,
    nesterov=True,
    weight_decay=0
)

# 3.2 validation
val_metrics = {}
val_predict = predict

validate_step = partial(compute_metrics, predict=val_predict,
                        load_x=load_x, load_y=load_y, ids=val_ids, metrics=val_metrics)

# 3.3 train
with_cc = False
logger = TBLogger(log_path=log_path)
criterion = weighted_cross_entropy_with_logits
train_kwargs = dict(lr=lr_policy, with_cc=with_cc, architecture=architecture, optimizer=optimizer, criterion=criterion)

checkpoint_manager = CheckpointManager(checkpoints_path, {
    **{k: v for k, v in train_kwargs.items() if isinstance(v, Policy)},
    'model.pth': architecture, 'optimizer.pth': optimizer
})

train_model = train(
    train_step=train_step_with_cc,
    batch_iter=batch_iter,
    n_epochs=n_epochs,
    logger=logger,
    checkpoint_manager=checkpoint_manager,
    validate=validate_step,
    **train_kwargs
)

# ### 5. RUN EXPERIMENT ###

predict_to_dir = partial(commands.predict, ids=test_ids, load_x=load_x, predict_fn=predict)
predict_logits_to_dir = partial(commands.predict, ids=test_ids, load_x=load_x, predict_fn=predict_logit)

command_evaluate_individual_metrics = partial(
    evaluate_individual_metrics_with_prc,
    load_y_true=identity,
    metrics=final_metrics,
    predictions_path=test_predictions_path,
    logits_path=logit_predictions_path,
)

seed = 0xBadCafe

# resource-manager execute sequence below:
# ##########################################
run_experiment = (
    fix_seed(seed),
    lock_dir(),
    architecture.to(device),
    if_missing(lambda p: [train_model, save_model_state(architecture, p)], saved_model_path),
    load_model_state(architecture, saved_model_path),
    if_missing(predict_logits_to_dir, output_path=logit_predictions_path),
    if_missing(predict_to_dir, output_path=test_predictions_path),
    if_missing(command_evaluate_individual_metrics, results_path='test_metrics'),
)
# ##########################################
